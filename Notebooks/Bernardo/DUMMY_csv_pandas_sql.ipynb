{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Setup",
   "id": "a2cfc118196c3ae9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-20T14:28:42.726030Z",
     "start_time": "2025-06-20T14:28:41.788457Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "data_folder = Path(\"Dummy_Data\")  # Adjust to where your dummy CSVs are stored\n",
    "db_path = Path(\"redezeit_dummy.db\")\n",
    "\n",
    "# Connect to the SQLite database (creates it if it doesn't exist)\n",
    "conn = sqlite3.connect(db_path)\n",
    "print(f\"Connected to SQLite DB at {db_path.resolve()}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to SQLite DB at C:\\Users\\Admin\\Documents\\Data_Craft_2024-25\\Projects\\Redezeit\\Redezeit-Analyse\\Notebooks\\Bernardo\\redezeit_dummy.db\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load Dummys",
   "id": "7f98dc5abf82d8a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T14:46:07.475932Z",
     "start_time": "2025-06-20T14:46:07.429284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Paths to dummy data folders\n",
    "dim_path = Path(r\"C:\\Users\\Admin\\Documents\\Data_Craft_2024-25\\Projects\\Redezeit\\Redezeit-Analyse\\Scripts\\Bernado\\Dummy_Data\\Dummy_Dim\")\n",
    "fact_path = Path(r\"C:\\Users\\Admin\\Documents\\Data_Craft_2024-25\\Projects\\Redezeit\\Redezeit-Analyse\\Scripts\\Bernado\\Dummy_Data\\Dummy_Fact\")\n",
    "\n",
    "# Dictionary with table name (no prefix) mapped to (subfolder path, filename)\n",
    "csv_files = {\n",
    "    \"dim_channel\": (dim_path, \"dummy_dim_channel.csv\"),\n",
    "    \"dim_continent\": (dim_path, \"dummy_dim_continent.csv\"),\n",
    "    \"dim_country\": (dim_path, \"dummy_dim_country.csv\"),\n",
    "    \"dim_date\":(dim_path, \"dummy_dim_date.csv\"),\n",
    "    \"dim_device\":(dim_path, \"dummy_dim_device.csv\"),\n",
    "    \"dim_event_name\":(dim_path, \"dummy_dim_event_name.csv\"),\n",
    "    \"dim_gender\":(dim_path, \"dummy_dim_gender.csv\"),\n",
    "    \"dim_page\":(dim_path, \"dummy_dim_page.csv\"),\n",
    "    \"dim_region\":(dim_path, \"dummy_dim_region.csv\"),\n",
    "    \"dim_source\":(dim_path, \"dummy_dim_source.csv\"),\n",
    "    \"fact_device_breakdown\":(fact_path, \"dummy_fact_device_breakdown.csv\"),\n",
    "    \"fact_gender_distribution\":(fact_path, \"dummy_fact_gender_distribution.csv\"),\n",
    "    \"fact_geo_data\":(fact_path, \"dummy_fact_geo_data.csv\"),\n",
    "    \"fact_interaction\":(fact_path, \"dummy_fact_interaction.csv\"),\n",
    "    \"fact_landing_page\":(fact_path, \"dummy_fact_landing_page.csv\"),\n",
    "    \"fact_origin_breakdown\":(fact_path, \"dummy_fact_origin_breakdown.csv\"),\n",
    "    \"fact_summary\": (fact_path, \"dummy_fact_summary.csv\"),\n",
    "    \"fact_visit_source\": (fact_path, \"dummy_fact_visit_source.csv\")\n",
    "}\n",
    "\n",
    "# Load into dictionary of DataFrames\n",
    "dfs = {}\n",
    "for table, (folder, filename) in csv_files.items():\n",
    "    path = folder / filename\n",
    "    df = pd.read_csv(path)\n",
    "    dfs[table] = df\n",
    "    print(f\"{table}: {df.shape[0]} rows loaded from {path.name}\")\n"
   ],
   "id": "831f2b2f6153c96d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_channel: 5 rows loaded from dummy_dim_channel.csv\n",
      "dim_continent: 5 rows loaded from dummy_dim_continent.csv\n",
      "dim_country: 5 rows loaded from dummy_dim_country.csv\n",
      "dim_date: 30 rows loaded from dummy_dim_date.csv\n",
      "dim_device: 3 rows loaded from dummy_dim_device.csv\n",
      "dim_event_name: 3 rows loaded from dummy_dim_event_name.csv\n",
      "dim_gender: 3 rows loaded from dummy_dim_gender.csv\n",
      "dim_page: 5 rows loaded from dummy_dim_page.csv\n",
      "dim_region: 5 rows loaded from dummy_dim_region.csv\n",
      "dim_source: 4 rows loaded from dummy_dim_source.csv\n",
      "fact_device_breakdown: 30 rows loaded from dummy_fact_device_breakdown.csv\n",
      "fact_gender_distribution: 30 rows loaded from dummy_fact_gender_distribution.csv\n",
      "fact_geo_data: 30 rows loaded from dummy_fact_geo_data.csv\n",
      "fact_interaction: 30 rows loaded from dummy_fact_interaction.csv\n",
      "fact_landing_page: 30 rows loaded from dummy_fact_landing_page.csv\n",
      "fact_origin_breakdown: 30 rows loaded from dummy_fact_origin_breakdown.csv\n",
      "fact_summary: 30 rows loaded from dummy_fact_summary.csv\n",
      "fact_visit_source: 30 rows loaded from dummy_fact_visit_source.csv\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Write all tables to SQLite",
   "id": "4ed28c4e520cf0c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T14:47:19.496225Z",
     "start_time": "2025-06-20T14:47:19.297045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Write DataFrames to SQLite\n",
    "for table, df in dfs.items():\n",
    "    df.to_sql(table, conn, if_exists=\"replace\", index=False)\n",
    "    print(f\"Table '{table}' written to SQLite.\")\n"
   ],
   "id": "3da28b077a0cd6d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'dim_channel' written to SQLite.\n",
      "Table 'dim_continent' written to SQLite.\n",
      "Table 'dim_country' written to SQLite.\n",
      "Table 'dim_date' written to SQLite.\n",
      "Table 'dim_device' written to SQLite.\n",
      "Table 'dim_event_name' written to SQLite.\n",
      "Table 'dim_gender' written to SQLite.\n",
      "Table 'dim_page' written to SQLite.\n",
      "Table 'dim_region' written to SQLite.\n",
      "Table 'dim_source' written to SQLite.\n",
      "Table 'fact_device_breakdown' written to SQLite.\n",
      "Table 'fact_gender_distribution' written to SQLite.\n",
      "Table 'fact_geo_data' written to SQLite.\n",
      "Table 'fact_interaction' written to SQLite.\n",
      "Table 'fact_landing_page' written to SQLite.\n",
      "Table 'fact_origin_breakdown' written to SQLite.\n",
      "Table 'fact_summary' written to SQLite.\n",
      "Table 'fact_visit_source' written to SQLite.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "verify",
   "id": "2892bb8c982587cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T14:47:40.178299Z",
     "start_time": "2025-06-20T14:47:40.167029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Show available tables in the SQLite DB\n",
    "query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "print(pd.read_sql(query, conn))\n"
   ],
   "id": "9272eb5bd57c02ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        name\n",
      "0                dim_channel\n",
      "1              dim_continent\n",
      "2                dim_country\n",
      "3                   dim_date\n",
      "4                 dim_device\n",
      "5             dim_event_name\n",
      "6                 dim_gender\n",
      "7                   dim_page\n",
      "8                 dim_region\n",
      "9                 dim_source\n",
      "10     fact_device_breakdown\n",
      "11  fact_gender_distribution\n",
      "12             fact_geo_data\n",
      "13          fact_interaction\n",
      "14         fact_landing_page\n",
      "15     fact_origin_breakdown\n",
      "16              fact_summary\n",
      "17         fact_visit_source\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sample Query",
   "id": "88a7034c71bcc15"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T14:48:09.338078Z",
     "start_time": "2025-06-20T14:48:09.276993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example query: total visits by device\n",
    "pd.read_sql(\"\"\"\n",
    "    SELECT Date, Mobile, Tablet, Desktop\n",
    "    FROM fact_device_breakdown\n",
    "    ORDER BY Date\n",
    "    LIMIT 5\n",
    "\"\"\", conn)\n"
   ],
   "id": "f31b9fdeb5e2387c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Date  Mobile  Tablet  Desktop\n",
       "0  2025-05-22     608    1334     1642\n",
       "1  2025-05-23     752    1388      765\n",
       "2  2025-05-24     521    1362      495\n",
       "3  2025-05-25    1192    1816      416\n",
       "4  2025-05-26    1729    1294     1792"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Mobile</th>\n",
       "      <th>Tablet</th>\n",
       "      <th>Desktop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>608</td>\n",
       "      <td>1334</td>\n",
       "      <td>1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>752</td>\n",
       "      <td>1388</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-24</td>\n",
       "      <td>521</td>\n",
       "      <td>1362</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-25</td>\n",
       "      <td>1192</td>\n",
       "      <td>1816</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>1729</td>\n",
       "      <td>1294</td>\n",
       "      <td>1792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
